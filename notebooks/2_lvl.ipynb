{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/massquantity/LibRecommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import implicit\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "import pandas as pd\n",
    "import ml_metrics as metrics\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_hist_df = pd.read_csv('../data/raw/movies_dataset_10 months.csv')\n",
    "\n",
    "user_hist_df['ts'] = pd.to_datetime(user_hist_df['ts'])\n",
    "user_hist_df['month'] = user_hist_df['ts'].dt.month\n",
    "\n",
    "test_1 = user_hist_df[user_hist_df['month'] == 6]\n",
    "test_2 = user_hist_df[user_hist_df['month'] == 7]\n",
    "user_hist_df = user_hist_df[user_hist_df['episode_id'] == 0]\n",
    "train = user_hist_df[~user_hist_df['month'].isin([6, 7])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_1 = test_1.drop_duplicates(['user_id', 'movie_id']).groupby('user_id')['movie_id'].apply(list).to_dict()\n",
    "correct_2 = test_2.drop_duplicates(['user_id', 'movie_id']).groupby('user_id')['movie_id'].apply(list).to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danil/Documents/github/sweet_RS/env/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "train['event'] = 1\n",
    "train = train[['user_id', 'movie_id', 'event']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_encode = {u: i for i, u in enumerate(train['user_id'].unique())}\n",
    "item_encode = {u: i for i, u in enumerate(train['movie_id'].unique())}\n",
    "\n",
    "user_decode = {v: k for k, v in user_encode.items()}\n",
    "item_decode = {v: k for k, v in item_encode.items()}\n",
    "\n",
    "n_users, n_items = len(user_encode), len(item_encode)\n",
    "\n",
    "train['user_id'] = train['user_id'].apply(lambda x: user_encode[x])\n",
    "train['movie_id'] = train['movie_id'].apply(lambda x: item_encode[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_user = coo_matrix(\n",
    "    (train['event'], (train['user_id'], train['movie_id'])), shape=(n_users, n_items))\n",
    "\n",
    "user_item = coo_matrix(\n",
    "    (train['event'], (train['movie_id'], train['user_id'])), shape=(n_items, n_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4063, 2055)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_item.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:OpenBLAS detected. Its highly recommend to set the environment variable 'export OPENBLAS_NUM_THREADS=1' to disable its internal multithreading\n"
     ]
    }
   ],
   "source": [
    "# initialize a model\n",
    "model = implicit.als.AlternatingLeastSquares(factors=5, iterations= 15)\n",
    "\n",
    "# train the model on a sparse matrix of item/user/confidence weights\n",
    "model.fit(user_item, show_progress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_database = pd.read_csv('../data/raw/movies.csv')\n",
    "useless_movies = movies_database[(movies_database['year'] < 2010) & \n",
    "                                 (~movies_database['id'].isin(list(item_encode.keys()))) &\n",
    "                                 (movies_database['imdb_rating'] < 6)]['id'].values\n",
    "\n",
    "useless_movies = [m for m in useless_movies if m in item_decode]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# als\n",
    "res = model.recommend_all(item_user, N = 100, filter_items = useless_movies, show_progress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "recom = {}\n",
    "\n",
    "for ind, rec in enumerate(res):\n",
    "    recom[user_decode[ind]] = [item_decode[x] for x in rec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14181012658227848"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# als\n",
    "reco = []\n",
    "corr = []\n",
    "\n",
    "num_to_recom = 5\n",
    "for user in correct_1:\n",
    "    try:\n",
    "        reco.append(recom[user])\n",
    "        corr.append(correct_1[user])\n",
    "    except:\n",
    "        print(user)\n",
    "        pass\n",
    "\n",
    "metrics.mapk(reco, corr, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features = model.user_factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get item features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danil/Documents/github/sweet_RS/env/lib/python3.7/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/danil/Documents/github/sweet_RS/env/lib/python3.7/site-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "movies_database = pd.read_csv('../data/raw/movies.csv')\n",
    "\n",
    "# movies_database = movies_database[movies_database['id'].isin(list(item_encode.keys()))]\n",
    "item_features = movies_database[['id', 'year', 'genres', 'imdb_rating', 'tmdb_rating']]\n",
    "\n",
    "def convert_year(val):\n",
    "    if val < 2000:\n",
    "        cat = 0\n",
    "    elif 2000<=val < 2010:\n",
    "        cat = 1\n",
    "    else:\n",
    "        cat = 2\n",
    "    return cat\n",
    "\n",
    "item_features['year'] = item_features['year'].apply(convert_year)\n",
    "\n",
    "user_hist_df = pd.read_csv('../data/raw/movies_dataset_10 months.csv')\n",
    "movies = user_hist_df[user_hist_df['episode_id'] == 0]['movie_id'].unique()\n",
    "\n",
    "item_features['movie'] = item_features['id'].apply(lambda x: 1 if x in movies else 0 )\n",
    "\n",
    "test = item_features['genres'].fillna('hz').str.split(',')\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "res = pd.DataFrame(mlb.fit_transform(test),\n",
    "                   columns=mlb.classes_,\n",
    "                   index=test.index)\n",
    "\n",
    "to_drop = ['Art House', 'Documentary', 'Family','Musical', 'Quarantine Info', 'hz', 'War']\n",
    "res = res.drop(to_drop, 1)\n",
    "\n",
    "item_features = pd.concat([item_features, res], 1).drop('genres', 1)\n",
    "\n",
    "item_features = item_features.fillna(item_features.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_features = item_features.drop('movie', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features_df = pd.DataFrame(user_features)\n",
    "user_features_df['user_id'] = user_encode.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_df = pd.merge(train, user_features_df, how='left', on='user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_df = pd.merge(rank_df, item_features, how = 'left', \n",
    "                   left_on ='movie_id', \n",
    "                   right_on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(184263, 34)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_df = rank_df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate negative examples\n",
    "\n",
    "2. from movies found 20 films from other genres \n",
    "3. and old ones, \n",
    "4. with small rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_hist = train.groupby('user_id')['movie_id'].apply(set)\n",
    "users_to_predict = train['user_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danil/Documents/github/sweet_RS/env/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "movie_genres = movies_database[['id', 'genres']]\n",
    "movie_genres['genres'] = movie_genres['genres'].str.split(',')\n",
    "#movie_genres['id'] = movie_genres['id'].apply(lambda x: item_encode.get(x, x + 1000000000) )\n",
    "\n",
    "movie_genres_dict = {}\n",
    "\n",
    "for i in movie_genres.iterrows():\n",
    "    movie_genres_dict[i[1][0]] = i[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_genres_dict = {k: v for k, v in movie_genres_dict.items() if isinstance(v, list)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "вот тут еще можно поиграться с кол вом жанров которые нужно учесть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_pref = {}\n",
    "for user in users_to_predict:\n",
    "    #print(user)\n",
    "    user_pref[user] = {}\n",
    "    #print(user_hist[user])\n",
    "    for film in user_hist[user]:\n",
    "        film = item_decode[film]\n",
    "        if movie_genres_dict.get(film):\n",
    "            for genre in movie_genres_dict[film]:\n",
    "                if user_pref[user].get(genre):\n",
    "                    user_pref[user][genre] += 1\n",
    "                else:\n",
    "                    user_pref[user][genre] = 1\n",
    "                    \n",
    "    user_pref[user] = [key for key, val in Counter(user_pref[user]).most_common(5)]                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_examples = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_negative = {}\n",
    "\n",
    "for user in user_pref:\n",
    "    negative = []\n",
    "    current_user_pref = set(user_pref[user])\n",
    "    \n",
    "    num = 0\n",
    "    while num < neg_examples:\n",
    "        random_film = random.sample(list(movie_genres_dict), 1)[0]\n",
    "        curr_film_genres = set(movie_genres_dict[random_film])\n",
    "        if len(current_user_pref.intersection(curr_film_genres)) == 0:\n",
    "            negative.append(random_film)\n",
    "            num += 1\n",
    "            \n",
    "    user_negative[user] = negative\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = []\n",
    "films = []\n",
    "\n",
    "\n",
    "for user in user_negative:\n",
    "    users += [user] * neg_examples\n",
    "    films += user_negative[user]\n",
    "    \n",
    "    \n",
    "negative_df = pd.DataFrame()\n",
    "negative_df['user_id'] = users\n",
    "negative_df['movie_id'] = films"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_df = pd.merge(negative_df, user_features_df, how='left', on='user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_df = pd.merge(negative_df, item_features, how = 'left', \n",
    "                       left_on ='movie_id', \n",
    "                       right_on='id')\n",
    "negative_df['event'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41100, 34)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(182074, 34)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = pd.concat([negative_df[:10000], rank_df[:10000]], 0)\n",
    "X = pd.concat([negative_df[:], rank_df[:]], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.iloc[:, 11:] = X.iloc[:, 11:].astype('int8')\n",
    "X.iloc[:, 2:7] = X.iloc[:, 2:7].astype('float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.drop(['user_id', 'movie_id', 'id', 'event'], 1), \n",
    "                                                    X['event'], test_size=0.2, random_state=42)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[:50000]\n",
    "y_train = y_train[:50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_train = [X_train.shape[0]]\n",
    "query_val = [X_val.shape[0]]\n",
    "query_test = [X_test.shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(142831, 30)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "del gbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = lgb.LGBMRanker(max_depth = 5, n_estimators = 20, random_state = 42, \n",
    "                    n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[1]\tvalid_0's ndcg@5: 1\tvalid_0's ndcg@10: 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[2]\tvalid_0's ndcg@5: 1\tvalid_0's ndcg@10: 1\n",
      "[3]\tvalid_0's ndcg@5: 1\tvalid_0's ndcg@10: 1\n",
      "[4]\tvalid_0's ndcg@5: 1\tvalid_0's ndcg@10: 1\n",
      "[5]\tvalid_0's ndcg@5: 1\tvalid_0's ndcg@10: 1\n",
      "[6]\tvalid_0's ndcg@5: 1\tvalid_0's ndcg@10: 1\n",
      "[7]\tvalid_0's ndcg@5: 1\tvalid_0's ndcg@10: 1\n",
      "[8]\tvalid_0's ndcg@5: 1\tvalid_0's ndcg@10: 1\n",
      "[9]\tvalid_0's ndcg@5: 1\tvalid_0's ndcg@10: 1\n",
      "[10]\tvalid_0's ndcg@5: 1\tvalid_0's ndcg@10: 1\n",
      "[11]\tvalid_0's ndcg@5: 1\tvalid_0's ndcg@10: 1\n",
      "[12]\tvalid_0's ndcg@5: 1\tvalid_0's ndcg@10: 1\n",
      "[13]\tvalid_0's ndcg@5: 1\tvalid_0's ndcg@10: 1\n",
      "[14]\tvalid_0's ndcg@5: 1\tvalid_0's ndcg@10: 1\n",
      "[15]\tvalid_0's ndcg@5: 1\tvalid_0's ndcg@10: 1\n",
      "[16]\tvalid_0's ndcg@5: 1\tvalid_0's ndcg@10: 1\n",
      "[17]\tvalid_0's ndcg@5: 1\tvalid_0's ndcg@10: 1\n",
      "[18]\tvalid_0's ndcg@5: 1\tvalid_0's ndcg@10: 1\n",
      "[19]\tvalid_0's ndcg@5: 1\tvalid_0's ndcg@10: 1\n",
      "[20]\tvalid_0's ndcg@5: 1\tvalid_0's ndcg@10: 1\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tvalid_0's ndcg@5: 1\tvalid_0's ndcg@10: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRanker(max_depth=5, n_estimators=20, n_jobs=4, random_state=42)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm.fit(X_train, y_train, group=query_train,\n",
    "        eval_set=[(X_val, y_val)], eval_group=[query_val],\n",
    "        eval_at=[5, 10], early_stopping_rounds=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = []\n",
    "films = []\n",
    "\n",
    "\n",
    "for user in recom:\n",
    "    users += [user_encode[user]] * 100\n",
    "    films += recom[user]\n",
    "    \n",
    "validate_df = pd.DataFrame()\n",
    "validate_df['user_id'] = users\n",
    "validate_df['movie_id'] = films"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_df = pd.merge(validate_df, user_features_df, how='left', on='user_id')\n",
    "\n",
    "validate_df = pd.merge(validate_df, item_features, how = 'left', \n",
    "                       left_on ='movie_id', \n",
    "                       right_on='id')\n",
    "\n",
    "\n",
    "validate_df = validate_df.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = gbm.predict(validate_df.drop(['user_id', 'movie_id', 'id'], 1))\n",
    "validate_df['pred'] = test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = validate_df.groupby(['user_id']).apply(lambda x: x.nlargest(5,['pred'])).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "recoms_wl = g.groupby('user_id')['movie_id'].apply(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.020493670886075947"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# als\n",
    "reco = []\n",
    "corr = []\n",
    "\n",
    "num_to_recom = 5\n",
    "for user in correct_1:\n",
    "    reco.append(recoms_wl[user_encode[user]])\n",
    "    corr.append(correct_1[user])\n",
    "\n",
    "metrics.mapk(reco, corr, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_hist_df = pd.read_csv('../data/raw/movies_dataset_10 months.csv')\n",
    "\n",
    "user_hist_df['ts'] = pd.to_datetime(user_hist_df['ts'])\n",
    "user_hist_df['month'] = user_hist_df['ts'].dt.month\n",
    "\n",
    "user_hist_df = user_hist_df[user_hist_df['episode_id'] == 0]\n",
    "train = train = user_hist_df[~user_hist_df['month'].isin([10, 11])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_hist_df['ts'] = pd.to_datetime(user_hist_df['ts'])\n",
    "user_hist_df['month'] = user_hist_df['ts'].dt.month\n",
    "\n",
    "test_1 = user_hist_df[user_hist_df['month'] == 6]\n",
    "test_2 = user_hist_df[user_hist_df['month'] == 7]\n",
    "user_hist_df = user_hist_df[user_hist_df['episode_id'] == 0]\n",
    "train = train = user_hist_df[~user_hist_df['month'].isin([6, 7])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danil/Documents/github/sweet_RS/env/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "train['event'] = 1\n",
    "train = train[['user_id', 'movie_id', 'event']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_encode = {u: i for i, u in enumerate(train['user_id'].unique())}\n",
    "item_encode = {u: i for i, u in enumerate(train['movie_id'].unique())}\n",
    "\n",
    "user_decode = {v: k for k, v in user_encode.items()}\n",
    "item_decode = {v: k for k, v in item_encode.items()}\n",
    "\n",
    "n_users, n_items = len(user_encode), len(item_encode)\n",
    "\n",
    "train['user_id'] = train['user_id'].apply(lambda x: user_encode[x])\n",
    "train['movie_id'] = train['movie_id'].apply(lambda x: item_encode[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_user = coo_matrix(\n",
    "    (train['event'], (train['user_id'], train['movie_id'])), shape=(n_users, n_items))\n",
    "\n",
    "user_item = coo_matrix(\n",
    "    (train['event'], (train['movie_id'], train['user_id'])), shape=(n_items, n_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4063, 2055)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_item.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:OpenBLAS detected. Its highly recommend to set the environment variable 'export OPENBLAS_NUM_THREADS=1' to disable its internal multithreading\n"
     ]
    }
   ],
   "source": [
    "# initialize a model\n",
    "model = implicit.als.AlternatingLeastSquares(factors=5, iterations= 15)\n",
    "\n",
    "# train the model on a sparse matrix of item/user/confidence weights\n",
    "model.fit(user_item, show_progress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_database = pd.read_csv('../data/raw/movies.csv')\n",
    "useless_movies = movies_database[(movies_database['year'] < 2010) & \n",
    "                                 (~movies_database['id'].isin(list(item_encode.keys()))) &\n",
    "                                 (movies_database['imdb_rating'] < 6)]['id'].values\n",
    "\n",
    "useless_movies = [m for m in useless_movies if m in item_decode]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# als\n",
    "res = model.recommend_all(item_user, N = 100, filter_items = useless_movies, show_progress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "recom = {}\n",
    "\n",
    "for ind, rec in enumerate(res):\n",
    "    recom[user_decode[ind]] = [item_decode[x] for x in rec]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features = model.user_factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get item features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danil/Documents/github/sweet_RS/env/lib/python3.7/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/Users/danil/Documents/github/sweet_RS/env/lib/python3.7/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "movies_database = pd.read_csv('../data/raw/movies.csv')\n",
    "\n",
    "# movies_database = movies_database[movies_database['id'].isin(list(item_encode.keys()))]\n",
    "item_features = movies_database[['id', 'year', 'genres', 'imdb_rating', 'tmdb_rating']]\n",
    "\n",
    "def convert_year(val):\n",
    "    if val < 2000:\n",
    "        cat = 0\n",
    "    elif 2000<=val < 2010:\n",
    "        cat = 1\n",
    "    else:\n",
    "        cat = 2\n",
    "    return cat\n",
    "\n",
    "item_features['year'] = item_features['year'].apply(convert_year)\n",
    "\n",
    "user_hist_df = pd.read_csv('../data/raw/movies_dataset_10 months.csv')\n",
    "movies = user_hist_df[user_hist_df['episode_id'] == 0]['movie_id'].unique()\n",
    "\n",
    "item_features['movie'] = item_features['id'].apply(lambda x: 1 if x in movies else 0 )\n",
    "\n",
    "test = item_features['genres'].fillna('hz').str.split(',')\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "res = pd.DataFrame(mlb.fit_transform(test),\n",
    "                   columns=mlb.classes_,\n",
    "                   index=test.index)\n",
    "\n",
    "to_drop = ['Art House', 'Documentary', 'Family','Musical', 'Quarantine Info', 'hz', 'War']\n",
    "res = res.drop(to_drop, 1)\n",
    "\n",
    "item_features = pd.concat([item_features, res], 1).drop('genres', 1)\n",
    "\n",
    "item_features = item_features.fillna(item_features.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_features = item_features.drop('movie', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features_df = pd.DataFrame(user_features)\n",
    "user_features_df['user_id'] = user_encode.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_df = pd.merge(train, user_features_df, how='left', on='user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_df = pd.merge(rank_df, item_features, how = 'left', \n",
    "                   left_on ='movie_id', \n",
    "                   right_on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(184263, 34)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_df = rank_df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate negative examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_hist = train.groupby('user_id')['movie_id'].apply(set)\n",
    "users_to_predict = train['user_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danil/Documents/github/sweet_RS/env/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "movie_genres = movies_database[['id', 'genres']]\n",
    "movie_genres['genres'] = movie_genres['genres'].str.split(',')\n",
    "#movie_genres['id'] = movie_genres['id'].apply(lambda x: item_encode.get(x, x + 1000000000) )\n",
    "\n",
    "movie_genres_dict = {}\n",
    "\n",
    "for i in movie_genres.iterrows():\n",
    "    movie_genres_dict[i[1][0]] = i[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_genres_dict = {k: v for k, v in movie_genres_dict.items() if isinstance(v, list)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "вот тут еще можно поиграться с кол вом жанров которые нужно учесть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_pref = {}\n",
    "for user in users_to_predict:\n",
    "    #print(user)\n",
    "    user_pref[user] = {}\n",
    "    #print(user_hist[user])\n",
    "    for film in user_hist[user]:\n",
    "        film = item_decode[film]\n",
    "        if movie_genres_dict.get(film):\n",
    "            for genre in movie_genres_dict[film]:\n",
    "                if user_pref[user].get(genre):\n",
    "                    user_pref[user][genre] += 1\n",
    "                else:\n",
    "                    user_pref[user][genre] = 1\n",
    "                    \n",
    "    user_pref[user] = [key for key, val in Counter(user_pref[user]).most_common(5)]                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_examples = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_negative = {}\n",
    "\n",
    "for user in user_pref:\n",
    "    negative = []\n",
    "    current_user_pref = set(user_pref[user])\n",
    "    \n",
    "    num = 0\n",
    "    while num < neg_examples:\n",
    "        random_film = random.sample(list(movie_genres_dict), 1)[0]\n",
    "        curr_film_genres = set(movie_genres_dict[random_film])\n",
    "        if len(current_user_pref.intersection(curr_film_genres)) == 0:\n",
    "            negative.append(random_film)\n",
    "            num += 1\n",
    "            \n",
    "    user_negative[user] = negative\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = []\n",
    "films = []\n",
    "\n",
    "\n",
    "for user in user_negative:\n",
    "    users += [user] * neg_examples\n",
    "    films += user_negative[user]\n",
    "    \n",
    "    \n",
    "negative_df = pd.DataFrame()\n",
    "negative_df['user_id'] = users\n",
    "negative_df['movie_id'] = films"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_df = pd.merge(negative_df, user_features_df, how='left', on='user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_df = pd.merge(negative_df, item_features, how = 'left', \n",
    "                       left_on ='movie_id', \n",
    "                       right_on='id')\n",
    "negative_df['event'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102750, 34)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(182074, 34)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = pd.concat([negative_df[:10000], rank_df[:10000]], 0)\n",
    "X = pd.concat([negative_df[:], rank_df[:]], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.iloc[:, 11:] = X.iloc[:, 11:].astype('int8')\n",
    "X.iloc[:, 2:7] = X.iloc[:, 2:7].astype('float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.drop(['user_id', 'movie_id', 'id', 'event'], 1), \n",
    "                                                    X['event'], test_size=0.2, random_state=42)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train[:100000]\n",
    "X_train = X_train[:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_train = [X_train.shape[0]]\n",
    "query_val = [X_val.shape[0]]\n",
    "query_test = [X_test.shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "del gbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = lgb.LGBMRanker(max_depth = 5, n_estimators = 20, random_state = 42, \n",
    "                    n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    }
   ],
   "source": [
    "gbm.fit(X_train, y_train, group=query_train,\n",
    "        eval_set=[(X_val, y_val)], eval_group=[query_val],\n",
    "        eval_at=[5, 10], early_stopping_rounds=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = []\n",
    "films = []\n",
    "\n",
    "\n",
    "for user in recom:\n",
    "    users += [user_encode[user]] * 100\n",
    "    films += recom[user]\n",
    "    \n",
    "validate_df = pd.DataFrame()\n",
    "validate_df['user_id'] = users\n",
    "validate_df['movie_id'] = films"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_df = pd.merge(validate_df, user_features_df, how='left', on='user_id')\n",
    "\n",
    "validate_df = pd.merge(validate_df, item_features, how = 'left', \n",
    "                       left_on ='movie_id', \n",
    "                       right_on='id')\n",
    "\n",
    "\n",
    "validate_df = validate_df.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = gbm.predict(validate_df.drop(['user_id', 'movie_id', 'id'], 1))\n",
    "validate_df['pred'] = test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = validate_df.groupby(['user_id']).apply(lambda x: x.nlargest(5,['pred'])).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "recoms_wl = g.groupby('user_id')['movie_id'].apply(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.020493670886075947"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# als\n",
    "reco = []\n",
    "corr = []\n",
    "\n",
    "num_to_recom = 5\n",
    "for user in correct_1:\n",
    "    reco.append(recoms_wl[user_encode[user]])\n",
    "    corr.append(correct_1[user])\n",
    "\n",
    "metrics.mapk(reco, corr, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_hist_df = pd.read_csv('../data/raw/movies_dataset_10 months.csv')\n",
    "user_hist_df = user_hist_df[user_hist_df['episode_id'] == 0]\n",
    "\n",
    "user_hist_df['event'] = 1\n",
    "train = user_hist_df[['user_id', 'movie_id', 'event']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_encode = {u: i for i, u in enumerate(train['user_id'].unique())}\n",
    "item_encode = {u: i for i, u in enumerate(train['movie_id'].unique())}\n",
    "\n",
    "user_decode = {v: k for k, v in user_encode.items()}\n",
    "item_decode = {v: k for k, v in item_encode.items()}\n",
    "\n",
    "n_users, n_items = len(user_encode), len(item_encode)\n",
    "\n",
    "train['user_id'] = train['user_id'].apply(lambda x: user_encode[x])\n",
    "train['movie_id'] = train['movie_id'].apply(lambda x: item_encode[x])\n",
    "\n",
    "item_user = coo_matrix(\n",
    "    (train['event'], (train['user_id'], train['movie_id'])), shape=(n_users, n_items))\n",
    "\n",
    "user_item = coo_matrix(\n",
    "    (train['event'], (train['movie_id'], train['user_id'])), shape=(n_items, n_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a model\n",
    "model = implicit.als.AlternatingLeastSquares(factors=5)\n",
    "\n",
    "# train the model on a sparse matrix of item/user/confidence weights\n",
    "model.fit(user_item, show_progress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = implicit.lmf.LogisticMatrixFactorization(factors = 5, random_state = 42)\n",
    "\n",
    "model.fit(user_item, show_progress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.recommend_all(item_user, N = 10, filter_items = useless_movies, show_progress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.recommend_all(item_user, N = 5, show_progress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "recom = {}\n",
    "\n",
    "for ind, rec in enumerate(res):\n",
    "    recom[user_decode[ind]] = [item_decode[x] for x in rec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "PATH = '/Users/danil/Documents/github/sweet_RS/'\n",
    "sys.path.append(str(PATH))\n",
    "\n",
    "from src.utils import save_to_pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_pickle(recom, '../data/processed/als_2_10.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
