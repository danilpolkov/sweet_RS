{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "PATH = '/Users/danil/Documents/github/sweet_RS/'\n",
    "sys.path.append(str(PATH))\n",
    "\n",
    "from src.utils import read_pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1695, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16975709365084587137</td>\n",
       "      <td>0 0 0 0 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10225505309438393880</td>\n",
       "      <td>0 0 0 0 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>337894458057354820</td>\n",
       "      <td>0 0 0 0 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16389753737490268206</td>\n",
       "      <td>0 0 0 0 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12377183607123393787</td>\n",
       "      <td>0 0 0 0 0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                user_id   movie_id\n",
       "0  16975709365084587137  0 0 0 0 0\n",
       "1  10225505309438393880  0 0 0 0 0\n",
       "2    337894458057354820  0 0 0 0 0\n",
       "3  16389753737490268206  0 0 0 0 0\n",
       "4  12377183607123393787  0 0 0 0 0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbmt = pd.read_csv('../data/raw/submission.csv')\n",
    "print(sbmt.shape)\n",
    "sbmt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# top 5 pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_pop = [12304, 7735, 15285, 17518, 19026]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = sbmt.copy()\n",
    "predict = predict.drop(' movie_id', 1)\n",
    "\n",
    "for ind, user in enumerate(sbmt.iterrows()):\n",
    "    #print(user[1]['user_id'])\n",
    "    \n",
    "    pred = ' '.join([str(i) for i in most_pop])\n",
    "    \n",
    "    predict.loc[ind, 'movie_id'] = pred\n",
    "    \n",
    "predict.to_csv('../data/submits/top_5.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 from top 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../data/processed/random_5_from_top100.pickle', 'rb') as f:\n",
    "    preds = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = sbmt.copy()\n",
    "predict = predict.drop(' movie_id', 1)\n",
    "\n",
    "for ind, user in enumerate(sbmt.iterrows()):\n",
    "    #print(user[1]['user_id'])\n",
    "    \n",
    "    pred = ' '.join([str(i) for i in preds[user[1]['user_id']]])\n",
    "    \n",
    "    predict.loc[ind, 'movie_id'] = pred\n",
    "    \n",
    "predict.to_csv('../data/submits/random_5_from_top_100.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lightFM baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preds = read_pickle('../data/processed/light_fm.pickle')\n",
    "preds = read_pickle('../data/processed/light_fm_new_idbm.pickle')\n",
    "\n",
    "predict = sbmt.copy()\n",
    "predict = predict.drop(' movie_id', 1)\n",
    "\n",
    "for ind, user in enumerate(sbmt.iterrows()):\n",
    "    #print(user[1]['user_id'])\n",
    "    \n",
    "    pred = ' '.join([str(i) for i in preds[user[1]['user_id']]])\n",
    "    \n",
    "    predict.loc[ind, 'movie_id'] = pred\n",
    "    \n",
    "predict.to_csv('../data/submits/light_fm_new_idbm.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LB 0.007"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lightFM tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = read_pickle('../data/processed/light_fm_tuned.pickle')\n",
    "\n",
    "predict = sbmt.copy()\n",
    "predict = predict.drop(' movie_id', 1)\n",
    "\n",
    "for ind, user in enumerate(sbmt.iterrows()):\n",
    "    #print(user[1]['user_id'])\n",
    "    \n",
    "    pred = ' '.join([str(i) for i in preds[user[1]['user_id']]])\n",
    "    \n",
    "    predict.loc[ind, 'movie_id'] = pred\n",
    "    \n",
    "predict.to_csv('../data/submits/light_fm_tuned.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LB 0.006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fav serials + lightFM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prepare top 5 serials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_hist_df = pd.read_csv('../data/raw/movies_dataset_10 months.csv')\n",
    "user_hist_df['ts'] = pd.to_datetime(user_hist_df['ts'])\n",
    "user_hist_df['month'] = user_hist_df['ts'].dt.month\n",
    "\n",
    "fav_serials = user_hist_df[(user_hist_df['episode_id'] != 0) & \n",
    "                           (user_hist_df['month'] == 7)].groupby(['user_id', 'movie_id'])['movie_id'].count()\n",
    "fav_serials = fav_serials[fav_serials>=2].reset_index(name='cnt')\n",
    "\n",
    "g = fav_serials.groupby([\"user_id\"]).apply(lambda x: x.sort_values([\"cnt\"], ascending = False)).reset_index(drop=True)\n",
    "\n",
    "user_top_5_serials = g.groupby([\"user_id\"])['movie_id'].apply(lambda x: list(x[:5])).to_dict()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load best lightFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = read_pickle('../data/processed/light_fm.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = read_pickle('../data/processed/light_fm_new_idbm.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = sbmt.copy()\n",
    "predict = predict.drop(' movie_id', 1)\n",
    "\n",
    "for ind, user in enumerate(sbmt.iterrows()):\n",
    "    \n",
    "    user_id = user[1]['user_id']\n",
    "    #print(user[1]['user_id'])\n",
    "    \n",
    "    \n",
    "    if user_top_5_serials.get(user_id):\n",
    "    \n",
    "        pref_serials = user_top_5_serials[user_id][:]\n",
    "        num_of_serials = len(pref_serials)\n",
    "\n",
    "        if num_of_serials < 5:\n",
    "            additional = 5 - num_of_serials\n",
    "            light_fm_pred = preds[user_id][:additional]\n",
    "\n",
    "            pred = pref_serials + light_fm_pred\n",
    "            \n",
    "        else:\n",
    "            pred = pref_serials\n",
    "    else:\n",
    "         pred = preds[user_id]\n",
    "            \n",
    "    pred = ' '.join([str(i) for i in pred])\n",
    "    \n",
    "    predict.loc[ind, 'movie_id'] = pred\n",
    "    \n",
    "predict.to_csv('../data/submits/fav_serials_light_fm_filtered_films_20.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LB 0.01339"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# covis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_hist_df_covis = user_hist_df[['user_id', 'movie_id']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_hist = user_hist_df_covis.groupby('user_id')['movie_id'].apply(set).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "covis = {}\n",
    "\n",
    "for user in user_hist:\n",
    "    curr_user_hist = user_hist[user]\n",
    "    for film in curr_user_hist:\n",
    "        if covis.get(film):\n",
    "            for other in curr_user_hist:\n",
    "                if other == film:\n",
    "                    continue\n",
    "                else:\n",
    "                    if covis[film].get(other):\n",
    "                        covis[film][other] += 1\n",
    "                    else:\n",
    "                        covis[film][other] = 1\n",
    "        else:\n",
    "            covis[film] = {}\n",
    "            for other in curr_user_hist:\n",
    "                if other == film:\n",
    "                    continue\n",
    "                else:\n",
    "                    if covis[film].get(other):\n",
    "                        covis[film][other] += 1\n",
    "                    else:\n",
    "                        covis[film][other] = 1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "covis_old = covis.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for film in covis:\n",
    "    covis[film] = dict(sorted(covis[film].items(), key = itemgetter(1), reverse = True)[:30]) \n",
    "    total = sum(covis[film].values())\n",
    "    for f in covis[film]:\n",
    "        covis[film][f]/=total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_for_user(covis, user_hist, user, N):\n",
    "    recoms = {}\n",
    "    for film in user_hist[user]:\n",
    "        cov = covis[film]\n",
    "        for rec in cov:\n",
    "            if recoms.get(rec):\n",
    "                recoms[rec] += covis[film][rec]\n",
    "            else:\n",
    "                recoms[rec] = covis[film][rec]\n",
    "    N_2 = N + 50\n",
    "    res = dict(sorted(recoms.items(), key = itemgetter(1), reverse = True)[:N_2]) \n",
    "    \n",
    "    res_f = list(set(res.keys()).difference(user_hist[user]))[:N]\n",
    "    return res_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1264, user_id      11254796898083103047\n",
      " movie_id               0 0 0 0 0\n",
      "Name: 1264, dtype: object)\n"
     ]
    }
   ],
   "source": [
    "predict = sbmt.copy()\n",
    "predict = predict.drop(' movie_id', 1)\n",
    "\n",
    "for ind, user in enumerate(sbmt.iterrows()):\n",
    "    #print(user[1]['user_id'])\n",
    "    \n",
    "    pred = pred_for_user(covis, user_hist, user[1]['user_id'], 5)\n",
    "    if len(pred)<5:\n",
    "        addit = 5 - len(pred)\n",
    "        pred += most_pop[:addit]\n",
    "        print(user)\n",
    "    pred = ' '.join([str(i) for i in pred])\n",
    "    \n",
    "    predict.loc[ind, 'movie_id'] = pred\n",
    "    \n",
    "predict.to_csv('../data/submits/covis.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LB 0.0031"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fav + covis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = sbmt.copy()\n",
    "predict = predict.drop(' movie_id', 1)\n",
    "\n",
    "for ind, user in enumerate(sbmt.iterrows()):\n",
    "    \n",
    "    user_id = user[1]['user_id']\n",
    "    #print(user[1]['user_id'])\n",
    "    \n",
    "    \n",
    "    if user_top_5_serials.get(user_id):\n",
    "    \n",
    "        pref_serials = user_top_5_serials[user_id]\n",
    "        num_of_serials = len(pref_serials)\n",
    "\n",
    "        if num_of_serials < 5:\n",
    "            additional = 5 - num_of_serials\n",
    "            covis_pred = pred_for_user(covis, user_hist, user_id, additional)\n",
    "\n",
    "            pred = pref_serials + covis_pred\n",
    "            \n",
    "        else:\n",
    "            pred = pref_serials\n",
    "    else:\n",
    "         pred = pred_for_user(covis, user_hist, user_id, 5)\n",
    "            \n",
    "    pred = ' '.join([str(i) for i in pred])\n",
    "    \n",
    "    predict.loc[ind, 'movie_id'] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict.to_csv('../data/submits/fav_serial_covis.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALS baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = read_pickle('../data/processed/als_2.pickle')\n",
    "\n",
    "predict = sbmt.copy()\n",
    "predict = predict.drop(' movie_id', 1)\n",
    "\n",
    "for ind, user in enumerate(sbmt.iterrows()):\n",
    "    #print(user[1]['user_id'])\n",
    "    \n",
    "    pred = ' '.join([str(i) for i in preds[user[1]['user_id']]])\n",
    "    \n",
    "    predict.loc[ind, 'movie_id'] = pred\n",
    "    \n",
    "predict.to_csv('../data/submits/als_2.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fav serials + ALS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prepare top 5 serials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_hist_df = pd.read_csv('../data/raw/movies_dataset_10 months.csv')\n",
    "user_hist_df['ts'] = pd.to_datetime(user_hist_df['ts'])\n",
    "user_hist_df['month'] = user_hist_df['ts'].dt.month\n",
    "\n",
    "fav_serials = user_hist_df[(user_hist_df['episode_id'] != 0) & \n",
    "                           (user_hist_df['month'] == 7)].groupby(['user_id', 'movie_id'])['movie_id'].count()\n",
    "fav_serials = fav_serials[fav_serials>=2].reset_index(name='cnt')\n",
    "\n",
    "g = fav_serials.groupby([\"user_id\"]).apply(lambda x: x.sort_values([\"cnt\"], ascending = False)).reset_index(drop=True)\n",
    "\n",
    "user_top_5_serials = g.groupby([\"user_id\"])['movie_id'].apply(lambda x: list(x[:5])).to_dict()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load best lightFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = read_pickle('../data/processed/als.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = sbmt.copy()\n",
    "predict = predict.drop(' movie_id', 1)\n",
    "\n",
    "for ind, user in enumerate(sbmt.iterrows()):\n",
    "    \n",
    "    user_id = user[1]['user_id']\n",
    "    #print(user[1]['user_id'])\n",
    "    \n",
    "    \n",
    "    if user_top_5_serials.get(user_id):\n",
    "    \n",
    "        pref_serials = user_top_5_serials[user_id][:3]\n",
    "        num_of_serials = len(pref_serials)\n",
    "\n",
    "        if num_of_serials < 5:\n",
    "            additional = 5 - num_of_serials\n",
    "            light_fm_pred = preds[user_id][:additional]\n",
    "\n",
    "            pred = pref_serials + light_fm_pred\n",
    "            \n",
    "        else:\n",
    "            pred = pref_serials\n",
    "    else:\n",
    "         pred = preds[user_id]\n",
    "            \n",
    "    pred = ' '.join([str(i) for i in pred])\n",
    "    \n",
    "    predict.loc[ind, 'movie_id'] = pred\n",
    "    \n",
    "predict.to_csv('../data/submits/fav_serials_3_als.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LMF baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = read_pickle('../data/processed/lmf.pickle')\n",
    "\n",
    "predict = sbmt.copy()\n",
    "predict = predict.drop(' movie_id', 1)\n",
    "\n",
    "for ind, user in enumerate(sbmt.iterrows()):\n",
    "    #print(user[1]['user_id'])\n",
    "    \n",
    "    pred = ' '.join([str(i) for i in preds[user[1]['user_id']]])\n",
    "    \n",
    "    predict.loc[ind, 'movie_id'] = pred\n",
    "    \n",
    "predict.to_csv('../data/submits/lmf.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
