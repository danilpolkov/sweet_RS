{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "PATH = '/Users/danil/Documents/github/sweet_RS/'\n",
    "sys.path.append(str(PATH))\n",
    "\n",
    "from src.utils import read_pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1695, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16975709365084587137</td>\n",
       "      <td>0 0 0 0 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10225505309438393880</td>\n",
       "      <td>0 0 0 0 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>337894458057354820</td>\n",
       "      <td>0 0 0 0 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16389753737490268206</td>\n",
       "      <td>0 0 0 0 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12377183607123393787</td>\n",
       "      <td>0 0 0 0 0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                user_id   movie_id\n",
       "0  16975709365084587137  0 0 0 0 0\n",
       "1  10225505309438393880  0 0 0 0 0\n",
       "2    337894458057354820  0 0 0 0 0\n",
       "3  16389753737490268206  0 0 0 0 0\n",
       "4  12377183607123393787  0 0 0 0 0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbmt = pd.read_csv('../data/raw/submission.csv')\n",
    "print(sbmt.shape)\n",
    "sbmt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# top 5 pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_pop = [12304, 7735, 15285, 17518, 19026]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = sbmt.copy()\n",
    "predict = predict.drop(' movie_id', 1)\n",
    "\n",
    "for ind, user in enumerate(sbmt.iterrows()):\n",
    "    #print(user[1]['user_id'])\n",
    "    \n",
    "    pred = ' '.join([str(i) for i in most_pop])\n",
    "    \n",
    "    predict.loc[ind, 'movie_id'] = pred\n",
    "    \n",
    "predict.to_csv('../data/submits/top_5.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 from top 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../data/processed/random_5_from_top100.pickle', 'rb') as f:\n",
    "    preds = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = sbmt.copy()\n",
    "predict = predict.drop(' movie_id', 1)\n",
    "\n",
    "for ind, user in enumerate(sbmt.iterrows()):\n",
    "    #print(user[1]['user_id'])\n",
    "    \n",
    "    pred = ' '.join([str(i) for i in preds[user[1]['user_id']]])\n",
    "    \n",
    "    predict.loc[ind, 'movie_id'] = pred\n",
    "    \n",
    "predict.to_csv('../data/submits/random_5_from_top_100.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lightFM baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preds = read_pickle('../data/processed/light_fm.pickle')\n",
    "preds = read_pickle('../data/processed/light_fm_new_idbm.pickle')\n",
    "\n",
    "predict = sbmt.copy()\n",
    "predict = predict.drop(' movie_id', 1)\n",
    "\n",
    "for ind, user in enumerate(sbmt.iterrows()):\n",
    "    #print(user[1]['user_id'])\n",
    "    \n",
    "    pred = ' '.join([str(i) for i in preds[user[1]['user_id']]])\n",
    "    \n",
    "    predict.loc[ind, 'movie_id'] = pred\n",
    "    \n",
    "predict.to_csv('../data/submits/light_fm_new_idbm.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LB 0.007"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lightFM tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = read_pickle('../data/processed/light_fm_tuned.pickle')\n",
    "\n",
    "predict = sbmt.copy()\n",
    "predict = predict.drop(' movie_id', 1)\n",
    "\n",
    "for ind, user in enumerate(sbmt.iterrows()):\n",
    "    #print(user[1]['user_id'])\n",
    "    \n",
    "    pred = ' '.join([str(i) for i in preds[user[1]['user_id']]])\n",
    "    \n",
    "    predict.loc[ind, 'movie_id'] = pred\n",
    "    \n",
    "predict.to_csv('../data/submits/light_fm_tuned.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LB 0.006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fav serials + lightFM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prepare top 5 serials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_hist_df = pd.read_csv('../data/raw/movies_dataset_10 months.csv')\n",
    "user_hist_df['ts'] = pd.to_datetime(user_hist_df['ts'])\n",
    "user_hist_df['month'] = user_hist_df['ts'].dt.month\n",
    "\n",
    "fav_serials = user_hist_df[(user_hist_df['episode_id'] != 0) & \n",
    "                           (user_hist_df['month'] == 7)].groupby(['user_id', 'movie_id'])['movie_id'].count()\n",
    "fav_serials = fav_serials[fav_serials>=2].reset_index(name='cnt')\n",
    "\n",
    "g = fav_serials.groupby([\"user_id\"]).apply(lambda x: x.sort_values([\"cnt\"], ascending = False)).reset_index(drop=True)\n",
    "\n",
    "user_top_5_serials = g.groupby([\"user_id\"])['movie_id'].apply(lambda x: list(x[:5])).to_dict()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load best lightFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = read_pickle('../data/processed/light_fm.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = read_pickle('../data/processed/light_fm_new_idbm.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = sbmt.copy()\n",
    "predict = predict.drop(' movie_id', 1)\n",
    "\n",
    "for ind, user in enumerate(sbmt.iterrows()):\n",
    "    \n",
    "    user_id = user[1]['user_id']\n",
    "    #print(user[1]['user_id'])\n",
    "    \n",
    "    \n",
    "    if user_top_5_serials.get(user_id):\n",
    "    \n",
    "        pref_serials = user_top_5_serials[user_id][:]\n",
    "        num_of_serials = len(pref_serials)\n",
    "\n",
    "        if num_of_serials < 5:\n",
    "            additional = 5 - num_of_serials\n",
    "            light_fm_pred = preds[user_id][:additional]\n",
    "\n",
    "            pred = pref_serials + light_fm_pred\n",
    "            \n",
    "        else:\n",
    "            pred = pref_serials\n",
    "    else:\n",
    "         pred = preds[user_id]\n",
    "            \n",
    "    pred = ' '.join([str(i) for i in pred])\n",
    "    \n",
    "    predict.loc[ind, 'movie_id'] = pred\n",
    "    \n",
    "predict.to_csv('../data/submits/fav_serials_light_fm_filtered_films_20.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LB 0.01339"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# covis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_hist_df_covis = user_hist_df[['user_id', 'movie_id']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_hist = user_hist_df_covis.groupby('user_id')['movie_id'].apply(set).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "covis = {}\n",
    "\n",
    "for user in user_hist:\n",
    "    curr_user_hist = user_hist[user]\n",
    "    for film in curr_user_hist:\n",
    "        if covis.get(film):\n",
    "            for other in curr_user_hist:\n",
    "                if other == film:\n",
    "                    continue\n",
    "                else:\n",
    "                    if covis[film].get(other):\n",
    "                        covis[film][other] += 1\n",
    "                    else:\n",
    "                        covis[film][other] = 1\n",
    "        else:\n",
    "            covis[film] = {}\n",
    "            for other in curr_user_hist:\n",
    "                if other == film:\n",
    "                    continue\n",
    "                else:\n",
    "                    if covis[film].get(other):\n",
    "                        covis[film][other] += 1\n",
    "                    else:\n",
    "                        covis[film][other] = 1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "covis_old = covis.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for film in covis:\n",
    "    covis[film] = dict(sorted(covis[film].items(), key = itemgetter(1), reverse = True)[:30]) \n",
    "    total = sum(covis[film].values())\n",
    "    for f in covis[film]:\n",
    "        covis[film][f]/=total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_for_user(covis, user_hist, user, N):\n",
    "    recoms = {}\n",
    "    for film in user_hist[user]:\n",
    "        cov = covis[film]\n",
    "        for rec in cov:\n",
    "            if recoms.get(rec):\n",
    "                recoms[rec] += covis[film][rec]\n",
    "            else:\n",
    "                recoms[rec] = covis[film][rec]\n",
    "    N_2 = N + 50\n",
    "    res = dict(sorted(recoms.items(), key = itemgetter(1), reverse = True)[:N_2]) \n",
    "    \n",
    "    res_f = list(set(res.keys()).difference(user_hist[user]))[:N]\n",
    "    return res_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1264, user_id      11254796898083103047\n",
      " movie_id               0 0 0 0 0\n",
      "Name: 1264, dtype: object)\n"
     ]
    }
   ],
   "source": [
    "predict = sbmt.copy()\n",
    "predict = predict.drop(' movie_id', 1)\n",
    "\n",
    "for ind, user in enumerate(sbmt.iterrows()):\n",
    "    #print(user[1]['user_id'])\n",
    "    \n",
    "    pred = pred_for_user(covis, user_hist, user[1]['user_id'], 5)\n",
    "    if len(pred)<5:\n",
    "        addit = 5 - len(pred)\n",
    "        pred += most_pop[:addit]\n",
    "        print(user)\n",
    "    pred = ' '.join([str(i) for i in pred])\n",
    "    \n",
    "    predict.loc[ind, 'movie_id'] = pred\n",
    "    \n",
    "predict.to_csv('../data/submits/covis.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LB 0.0031"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fav + covis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = sbmt.copy()\n",
    "predict = predict.drop(' movie_id', 1)\n",
    "\n",
    "for ind, user in enumerate(sbmt.iterrows()):\n",
    "    \n",
    "    user_id = user[1]['user_id']\n",
    "    #print(user[1]['user_id'])\n",
    "    \n",
    "    \n",
    "    if user_top_5_serials.get(user_id):\n",
    "    \n",
    "        pref_serials = user_top_5_serials[user_id]\n",
    "        num_of_serials = len(pref_serials)\n",
    "\n",
    "        if num_of_serials < 5:\n",
    "            additional = 5 - num_of_serials\n",
    "            covis_pred = pred_for_user(covis, user_hist, user_id, additional)\n",
    "\n",
    "            pred = pref_serials + covis_pred\n",
    "            \n",
    "        else:\n",
    "            pred = pref_serials\n",
    "    else:\n",
    "         pred = pred_for_user(covis, user_hist, user_id, 5)\n",
    "            \n",
    "    pred = ' '.join([str(i) for i in pred])\n",
    "    \n",
    "    predict.loc[ind, 'movie_id'] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict.to_csv('../data/submits/fav_serial_covis.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALS baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = read_pickle('../data/processed/als_2.pickle')\n",
    "\n",
    "predict = sbmt.copy()\n",
    "predict = predict.drop(' movie_id', 1)\n",
    "\n",
    "for ind, user in enumerate(sbmt.iterrows()):\n",
    "    #print(user[1]['user_id'])\n",
    "    \n",
    "    pred = ' '.join([str(i) for i in preds[user[1]['user_id']]])\n",
    "    \n",
    "    predict.loc[ind, 'movie_id'] = pred\n",
    "    \n",
    "predict.to_csv('../data/submits/als_2.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fav serials + ALS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prepare top 5 serials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_hist_df = pd.read_csv('../data/raw/movies_dataset_10 months.csv')\n",
    "user_hist_df['ts'] = pd.to_datetime(user_hist_df['ts'])\n",
    "user_hist_df['month'] = user_hist_df['ts'].dt.month\n",
    "\n",
    "fav_serials = user_hist_df[(user_hist_df['episode_id'] != 0) & \n",
    "                           (user_hist_df['month'] == 7)].groupby(['user_id', 'movie_id'])['movie_id'].count()\n",
    "fav_serials = fav_serials[fav_serials>=3].reset_index(name='cnt')\n",
    "\n",
    "g = fav_serials.groupby([\"user_id\"]).apply(lambda x: x.sort_values([\"cnt\"], ascending = False)).reset_index(drop=True)\n",
    "\n",
    "user_top_5_serials = g.groupby([\"user_id\"])['movie_id'].apply(lambda x: list(x[:5])).to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = read_pickle('../data/processed/als_2.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = sbmt.copy()\n",
    "predict = predict.drop(' movie_id', 1)\n",
    "\n",
    "for ind, user in enumerate(sbmt.iterrows()):\n",
    "    \n",
    "    user_id = user[1]['user_id']\n",
    "    #print(user[1]['user_id'])\n",
    "    \n",
    "    \n",
    "    if user_top_5_serials.get(user_id):\n",
    "    \n",
    "        pref_serials = user_top_5_serials[user_id][:]\n",
    "        num_of_serials = len(pref_serials)\n",
    "\n",
    "        if num_of_serials < 5:\n",
    "            additional = 5 - num_of_serials\n",
    "            light_fm_pred = preds[user_id][:additional]\n",
    "\n",
    "            pred = pref_serials + light_fm_pred\n",
    "            \n",
    "        else:\n",
    "            pred = pref_serials\n",
    "    else:\n",
    "         pred = preds[user_id]\n",
    "            \n",
    "    pred = ' '.join([str(i) for i in pred])\n",
    "    \n",
    "    predict.loc[ind, 'movie_id'] = pred\n",
    "    \n",
    "predict.to_csv('../data/submits/fav_serials_3_als_2.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LMF baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = read_pickle('../data/processed/lmf.pickle')\n",
    "\n",
    "predict = sbmt.copy()\n",
    "predict = predict.drop(' movie_id', 1)\n",
    "\n",
    "for ind, user in enumerate(sbmt.iterrows()):\n",
    "    #print(user[1]['user_id'])\n",
    "    \n",
    "    pred = ' '.join([str(i) for i in preds[user[1]['user_id']]])\n",
    "    \n",
    "    predict.loc[ind, 'movie_id'] = pred\n",
    "    \n",
    "predict.to_csv('../data/submits/lmf.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fav serial + item simil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = read_pickle('../data/processed/item_simil_10.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = sbmt.copy()\n",
    "predict = predict.drop(' movie_id', 1)\n",
    "\n",
    "for ind, user in enumerate(sbmt.iterrows()):\n",
    "    \n",
    "    user_id = user[1]['user_id']\n",
    "    #print(user[1]['user_id'])\n",
    "    \n",
    "    \n",
    "    if user_top_5_serials.get(user_id):\n",
    "    \n",
    "        pref_serials = user_top_5_serials[user_id][:]\n",
    "        num_of_serials = len(pref_serials)\n",
    "\n",
    "        if num_of_serials < 5:\n",
    "            additional = 5 - num_of_serials\n",
    "            light_fm_pred = preds[user_id][:additional]\n",
    "\n",
    "            pred = pref_serials + light_fm_pred\n",
    "            \n",
    "        else:\n",
    "            pred = pref_serials\n",
    "    else:\n",
    "         pred = preds[user_id][:5]\n",
    "            \n",
    "    pred = ' '.join([str(i) for i in pred])\n",
    "    \n",
    "    predict.loc[ind, 'movie_id'] = pred\n",
    "    \n",
    "predict.to_csv('../data/submits/fav_serials_item_simil.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16975709365084587137</td>\n",
       "      <td>17729 18262 18611 18507 18964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10225505309438393880</td>\n",
       "      <td>17079 13122 17850 3506 13950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>337894458057354820</td>\n",
       "      <td>16676 16830 17186 16829 17999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16389753737490268206</td>\n",
       "      <td>17909 19954 19279 18548 18423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12377183607123393787</td>\n",
       "      <td>18652 18308 18520 18153 18413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1690</th>\n",
       "      <td>16073255054457636768</td>\n",
       "      <td>16757 18534 7351 17966 13378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1691</th>\n",
       "      <td>18217982949448186449</td>\n",
       "      <td>18534 17966 7347 17756 13378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1692</th>\n",
       "      <td>8493046014808115881</td>\n",
       "      <td>18652 18413 18520 9311 18807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1693</th>\n",
       "      <td>6524731807859816855</td>\n",
       "      <td>18520 18413 18652 9311 18153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1694</th>\n",
       "      <td>17611799088817908833</td>\n",
       "      <td>18534 7347 10584 17966 7351</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1695 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   user_id                       movie_id\n",
       "0     16975709365084587137  17729 18262 18611 18507 18964\n",
       "1     10225505309438393880   17079 13122 17850 3506 13950\n",
       "2       337894458057354820  16676 16830 17186 16829 17999\n",
       "3     16389753737490268206  17909 19954 19279 18548 18423\n",
       "4     12377183607123393787  18652 18308 18520 18153 18413\n",
       "...                    ...                            ...\n",
       "1690  16073255054457636768   16757 18534 7351 17966 13378\n",
       "1691  18217982949448186449   18534 17966 7347 17756 13378\n",
       "1692   8493046014808115881   18652 18413 18520 9311 18807\n",
       "1693   6524731807859816855   18520 18413 18652 9311 18153\n",
       "1694  17611799088817908833    18534 7347 10584 17966 7351\n",
       "\n",
       "[1695 rows x 2 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# common in top 10 from als_2, item2item, light_fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preds = read_pickle('../data/processed/light_fm.pickle')\n",
    "als = read_pickle('../data/processed/als_2_10.pickle')\n",
    "ite2item = read_pickle('../data/processed/item_simil_10.pickle')\n",
    "light_fm = read_pickle('../data/processed/light_fm_new_idbm_10.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7347, 7351, 18080]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x[0] for x in pred if x[1] >= 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = sbmt.copy()\n",
    "predict = predict.drop(' movie_id', 1)\n",
    "\n",
    "for ind, user in enumerate(sbmt.iterrows()):\n",
    "    user = user[1]['user_id']\n",
    "    \n",
    "    #pred = Counter(als[user] + ite2item[user] + light_fm[user]).most_common(5)\n",
    "    pred = Counter(als[user] + light_fm[user]).most_common(5)\n",
    "    pred = [x[0] for x in pred if x[1] >= 2]\n",
    "    \n",
    "    if len(pred) < 5:\n",
    "        additional = 5 - len(pred)\n",
    "        light_fm_pred = light_fm[user][:additional]\n",
    "\n",
    "        pred += light_fm_pred\n",
    "    \n",
    "    pred = ' '.join([str(i) for i in pred])\n",
    "    \n",
    "    predict.loc[ind, 'movie_id'] = pred\n",
    "    \n",
    "predict.to_csv('../data/submits/ensemble_als_lightfm.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2_lvl baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../data/processed/random_5_from_top100.pickle', 'rb') as f:\n",
    "    random_preds = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random\n",
      "random\n",
      "random\n",
      "random\n",
      "random\n",
      "random\n",
      "random\n",
      "random\n",
      "random\n",
      "random\n",
      "random\n",
      "random\n",
      "random\n",
      "random\n",
      "random\n"
     ]
    }
   ],
   "source": [
    "#preds = read_pickle('../data/processed/2_lvl_30000.pickle')\n",
    "preds = read_pickle('../data/processed/2_lvl_xgbm.pickle')\n",
    "\n",
    "predict = sbmt.copy()\n",
    "predict = predict.drop(' movie_id', 1)\n",
    "\n",
    "for ind, user in enumerate(sbmt.iterrows()):\n",
    "    #print(user[1]['user_id'])\n",
    "    user = user[1]['user_id']\n",
    "    \n",
    "    if preds.get(user):\n",
    "        #pred = ' '.join([str(i) for i in preds[user]])\n",
    "        pred = preds[user]\n",
    "    elif user_top_5_serials.get(user):\n",
    "        print('top_5')\n",
    "        if len(user_top_5_serials[user]) < 5:\n",
    "            additional = len(user_top_5_serials[user]) - 5\n",
    "            addit = random_preds[user][:additional]\n",
    "            \n",
    "            pred = user_top_5_serials[user] + addit\n",
    "    else:\n",
    "        print('random')\n",
    "        pred = random_preds[user][:5]\n",
    "\n",
    "    pred = ' '.join([str(i) for i in pred])\n",
    "    \n",
    "    predict.loc[ind, 'movie_id'] = pred\n",
    "    \n",
    "predict.to_csv('../data/submits/2_lvl_xgbm.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16975709365084587137</td>\n",
       "      <td>19252 16693 16032 10447 17550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10225505309438393880</td>\n",
       "      <td>19252 2973 10337 2164 2165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>337894458057354820</td>\n",
       "      <td>17261 10920 9335 19207 16032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16389753737490268206</td>\n",
       "      <td>17261 16693 2973 10920 19252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12377183607123393787</td>\n",
       "      <td>10920 19383 19207 17041 9408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1690</th>\n",
       "      <td>16073255054457636768</td>\n",
       "      <td>19353 15679 16601 17261 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1691</th>\n",
       "      <td>18217982949448186449</td>\n",
       "      <td>10920 5 19207 18576 9256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1692</th>\n",
       "      <td>8493046014808115881</td>\n",
       "      <td>17261 10920 9335 9221 2973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1693</th>\n",
       "      <td>6524731807859816855</td>\n",
       "      <td>17261 9335 10920 19207 17041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1694</th>\n",
       "      <td>17611799088817908833</td>\n",
       "      <td>19207 19252 16734 10920 16032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1695 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   user_id                       movie_id\n",
       "0     16975709365084587137  19252 16693 16032 10447 17550\n",
       "1     10225505309438393880     19252 2973 10337 2164 2165\n",
       "2       337894458057354820   17261 10920 9335 19207 16032\n",
       "3     16389753737490268206   17261 16693 2973 10920 19252\n",
       "4     12377183607123393787   10920 19383 19207 17041 9408\n",
       "...                    ...                            ...\n",
       "1690  16073255054457636768      19353 15679 16601 17261 5\n",
       "1691  18217982949448186449       10920 5 19207 18576 9256\n",
       "1692   8493046014808115881     17261 10920 9335 9221 2973\n",
       "1693   6524731807859816855   17261 9335 10920 19207 17041\n",
       "1694  17611799088817908833  19207 19252 16734 10920 16032\n",
       "\n",
       "[1695 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
